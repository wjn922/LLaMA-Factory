### model
model_name_or_path: pretrained_models/Qwen3-VL-4B-LLaVAOV-Stage1.5-New/
flash_attn: fa2
# image_max_pixels: 12845056 # 16384*28*28 (3584x3584)
image_max_pixels: 1048576 # 16384*28*28 (1024x1024)
video_max_pixels: 16384
trust_remote_code: true

### method
stage: sft
do_train: true
finetuning_type: full
freeze_vision_tower: false
freeze_multi_modal_projector: false
freeze_language_model: false
deepspeed: examples/deepspeed/ds_z3_config.json # use z2 config 

### dataset
dataset: llava_next_780k
# dataset_dir: data  # default: data/, for readding dataset_info.json
template: qwen3_vl
cutoff_len: 32768
# max_samples: 1000 
overwrite_cache: true
preprocessing_num_workers: 16
dataloader_num_workers: 8
streaming: true # enable dataset streaming to handle large dataset
# buffer_size: 500 # size of the buffer to randomly sample examples from in dataset streaming

### output
output_dir: output/qwen3vl-4b_llava-next_4x8x7_lr2e-5
logging_steps: 10
save_steps: 1000
plot_loss: true
overwrite_output_dir: true
save_only_model: false
report_to: wandb  # choices: [none, wandb, tensorboard, swanlab, mlflow]
run_name: qwen3vl-4b_llava-next_4x8x7_lr2e-5

### train
per_device_train_batch_size: 2
gradient_accumulation_steps: 14
learning_rate: 2.0e-5
# num_train_epochs: 1.0
max_steps: 3500 # step-based training
accelerator_config:
  dispatch_batches: false   # set dispatch batches to false when use streaming dataset
lr_scheduler_type: cosine_with_min_lr
lr_scheduler_kwargs:
  min_lr: 1.0e-6  # minimum learning rate, same as LLaVA-OV
warmup_ratio: 0.03
bf16: true
ddp_timeout: 180000000
resume_from_checkpoint: null # if not set, will auto resume by default if output_dir is not empty
disable_gradient_checkpointing: true # to handle gradient ckpt bug in llavaov

### optimizer
optim: adamw_torch 
adam_beta1: 0.9  # 默认值，显式声明
adam_beta2: 0.999  # 默认值
adam_epsilon: 1.0e-8  # 默认值
weight_decay: 0 # 设置为0，和官方对齐
max_grad_norm: 1.0  # 默认值，显式声明


### eval
# val_size: 0.1
# per_device_eval_batch_size: 1
# eval_strategy: steps
# eval_steps: 500